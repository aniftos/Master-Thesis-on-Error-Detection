# Master-Thesis-on-Error-Detection

Human-Robot interactions (HRI) these days are far from being perfect. Sooner or later error situations will occur. Giving robots the ability of detecting errors followed by a recovery strategy in human-robot interactions is essential for a more naturalistic and a higher quality interaction.

This thesis studies a novel approach for automatic error detection in human-robot interactions. This approach detects errors based on human facial expressions while humans interact with erroneous robots. To achieve that, a Wizard-of-Oz (WOz) user study was conducted in which 25 participants interacted with a robot that was programmed to show some error behaviours. During the study, using a ZED camera the facial expressions and reactions of the participants were recorded. Once all the video data were collected, ELAN 2.5 was used to annotate them. Two cases were created, the Error and No Error situations. Using the ffmpeg software the desirable video parts were cropped. In total, using 30 frames per second for video recording 314,100 frames were collected, where 38,398 from those frames were picked for No Error situations while 36,435 frames for Error situations. Using the OpenPose library 70 facial keypoints were extracted for every frame and the displacements between same keypoints of successive frames were calculated. Two types of datasets were developed, with and without temporal information. Moreover, Principal Component Analysis for dimensionality reduction was used in both datasets to check for further improvements in the models' accuracy. Using the datasets, I trained a Support Vector Machine, Random Forest, Naive Bayes and a Long-Short Term Memory Neural Network and evaluated the classifiers using 5-fold cross validation. The results of the evaluation suggest that in general the error detection is partly working but the accuracy is not great.  Naive Bayes with the use of the dataset with temporal information and PCA outperformed the other models achieving 60\% accuracy and 59% average F1 score.

Furthermore, I proceed with a discussion regarding the results and the possible reasons that affected the accuracies of the systems. I suggested several directions to be followed for future works such as the development of different features sets that will include face and body keypoints and the addition of the direction of the movement.